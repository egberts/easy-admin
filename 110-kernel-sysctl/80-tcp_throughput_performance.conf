#
# File: 80-tcp_throughput_performance.conf
# Path: /etc/sysctl.d
# Title: TCP throughput improvement
# Creator: 79-sysctl-net-performance.sh
# Date: Thu Feb 17 05:11:41 PM EST 2022
# Reference:
#  - https://www.uperf.org
#
# tcp_allowed_congestion_control - STRING
#    Show/set the congestion control choices available to non-privileged
#    processes. The list is a subset of those listed in
#    tcp_available_congestion_control.
#
# The default algorithm for most kernel is 'reno'.
# After 13 variants of TCP congestion control, cubic is the best

net.ipv4.tcp_congestion_control = cubic

# tcp_fin_timeout parameter determines the length of
# time an orphaned (unreferenced) connection will wait
# before it is aborted at the local end.  This
# parameter is especially helpful for when something
# happens to the remote peer which prevents or
# excessively delays a response.  Since each socket
# used for connections consumes approxibately 1.5K
# bytes of memory, the kernel must pro-actively abort
# and purge dead or stale resources.
net.ipv4.tcp_fin_timeout = 1

# TCP controls small queue limits on per TCP-socket
# basis.  TCP tends to increase the data in-flight
# until loss notifications are received.  With aspects
# of TCP send auto-tuning, large amounts of data might
# get queued at the device on the local machine, which
# can adversely impact the latency for other streams.
# tcp_limit_output_bytes limits the number of bytes on
# a device to reduce the latency effects caused by a
# larger queue size.
# The default value is 262,144 bytes.  For workloads
# or environments where latency is higher priority
# than throughput, lower this value can improve
# latency.
net.ipv4.tcp_limit_output_bytes = 131072

# The normal TCP stack behavior is set to favor
# decisions that maximize network throughput.
# tcp_low_latency parameter, when set, tells TCP to
# instead make decisions that would prefer lower
# latency.
# The default value is 0(off).  For workloads or
# environments where latency is a higher priority, the
# recommended value is 1 (on).
net.ipv4.tcp_low_latency = 0

# tcp_max_tw_buckets specifies the maximum number of
# sockets in the "time-wait" state allowed to exist at
# any time.  If the maimum value is exceeded, sockets
# in the "time-wait" state are immediately destroyed
# and a warning is displayed.  This setting exists to
# thwart certain type of "Denial of Service" attacks.
# Care should be exercised before lowering this value.
# When changed, its value should be increased,
# especially when more memory has been added to the
# system or when the network demands are high and
# environment is less exposed to external threats.
net.ipv4.tcp_max_tw_buckets = 450000

# tcp_tw_reuse permits sockets in the "time-wait"
# state to be reused for new connections.  In high
# traffic environments, sockets are created and
# destroyed at very high rates.  This parameter, when
# set, allows "no longer neded" and "about to be
# destroyed" sockets to be used for new connections.
# When enabled, this parameter can bypass the
# allocation and initialization overhead normally
# associated with socket creation saving CPU cycles,
# system load and time.
net.ipv4.tcp_tw_reuse = 1

# We are not worried about 2GB rollover and recovering any lost packet before
net.ipv4.tcp_timestamps = 0

# tcp_max_syn_backlog - INTEGER
#    Maximal number of remembered connection requests (SYN_RECV),
#    which have not received an acknowledgment from connecting client.
#
#    This is a per-listener limit.
#
#    The minimal value is 128 for low memory machines, and it will
#    increase in proportion to the memory of machine.
#
#    If server suffers from overload, try increasing this number.
#
#    Remember to also check /proc/sys/net/core/somaxconn
#    A SYN_RECV request socket consumes about 304 bytes of memory.
#
# Setting large number of incoming TCP connection requests

net.ipv4.tcp_max_syn_backlog=3000

